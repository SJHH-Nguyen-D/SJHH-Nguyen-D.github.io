<!DOCTYPE html>
<html lang="en">

<head>
      <meta charset="utf-8">
  <meta http-equiv="Content-Type" content="text/html" charset="UTF-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />


  <title>Ever wondered what your employee performance score would be? Part 6: Imputation of Missing Data</title>

  <meta name="description" content="My name is Dennis Nguyen-Do. This is my personal blog." />

  <meta name="HandheldFriendly" content="True" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <meta name="referrer" content="origin" />
  <meta name="generator" content="Pelican" />
  <link href="" rel="canonical" />

  <!-- Feed -->

  <link href="/theme/css/style.css" type="text/css" rel="stylesheet" />

  <!-- Code highlight color scheme -->
      <link href="/theme/css/code_blocks/github.css" rel="stylesheet">


  <!-- Custom fonts -->
  <link href='https://fonts.googleapis.com/css?family=Montserrat:400,300' rel='stylesheet' type='text/css' />
  <link href="https://fonts.googleapis.com/css?family=Lato" rel="stylesheet" type="text/css" />

  <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
  <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
  <!--[if lt IE 9]>
    <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
    <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
  <![endif]-->


    <link href="/2019/10/sharpestminds-project-part-6.html" rel="canonical" />

        <meta name="description" content="This is the sixth post of my SharpestMinds project series talk about missing data values and how to come up with a smarter way to go...">

        <meta name="author" content="Nguyen-Do, Dennis">

        <meta name="tags" content="sharpestminds-project">
        <meta name="tags" content="data science">
        <meta name="tags" content="projects">
        <meta name="tags" content="employee performance">
        <meta name="tags" content="preprocessing">
        <meta name="tags" content="missing data">
        <meta name="tags" content="imputation">
        <meta name="tags" content="impute">
        <meta name="tags" content="missingpy">

        <meta property="og:locale" content="" />
    <meta property="og:site_name" content="Denny-4/7 Data Science Blog" />
    <meta property="og:type" content="website" />
    <meta property="og:title" content="Denny-4/7 Data Science Blog" />
    <meta property="og:description" content="View the blog." />
    <meta property="og:url" content="" />
      <meta property="og:image" content="//assets/head_cover_general.jpg" />

  <meta property="og:type" content="article">
            <meta property="article:author" content="/author/nguyen-do-dennis">
  <meta property="og:url" content="/2019/10/sharpestminds-project-part-6.html">
  <meta property="og:title" content="Ever wondered what your employee performance score would be? Part 6: Imputation of Missing Data">
  <meta property="article:published_time" content="2019-10-28 18:45:00-05:00">
            <meta property="og:description" content="This is the sixth post of my SharpestMinds project series talk about missing data values and how to come up with a smarter way to go...">

            <meta property="og:image" content="//assets/head_cover_general.jpg">
        <meta name="twitter:card" content="summary_large_image">
        <meta name="twitter:site" content="@Dennis00481552">
        <meta name="twitter:title" content="Ever wondered what your employee performance score would be? Part 6: Imputation of Missing Data">
        <meta name="twitter:url" content="/2019/10/sharpestminds-project-part-6.html">

            <meta name="twitter:image:src" content="//assets/head_cover_general.jpg">

            <meta name="twitter:description" content="This is the sixth post of my SharpestMinds project series talk about missing data values and how to come up with a smarter way to go...">
</head>
<!-- TODO : Body class -->
<body class="home-template">

<nav id="menu">
  <a class="close-button">Close</a>
  <div class="nav-wrapper">
    <p class="nav-label">Menu</p>
    <ul>

          <ul>
              <li role="presentation"><a href="/pages/about.html">About</a></li>
          <ul>
              <li role="presentation"><a href="/pages/contact.html">Contact</a></li>
              <li class="nav-archives active" role="presentation"><a href="/archives.html">Archives</a></li>
          </ul>

    </ul>
  </div>
</nav>
    <!-- Progressbar -->
    <div class="progress-container">
        <span class="progress-bar"></span>
    </div>

    <!-- Page Header -->
    <!-- Set your background image for this header on the line below. -->
    <header id="post-header" class="has-cover">
      <div class="inner">
        <nav id="navigation">
            <span id="home-button" class="nav-button">
                <!-- <a class="home-button" href="" title="Home"><i class="ic ic-arrow-left"></i> Home</a> -->
                <a class="home-button" href="/index.html" title="Home"><i class="ic ic-arrow-left"></i> Home</a>
            </span>
          <span id="menu-button" class="nav-button">
            <a class="menu-button"><i class="ic ic-menu"></i> Menu</a>
          </span>
        </nav>
        <h1 class="post-title">Ever wondered what your employee performance score would be? Part 6: Imputation of Missing Data</h1>
        <!-- TODO : Proper class for headline -->
        <span class="post-meta">
                <a href="/author/nguyen-do-dennis">Nguyen-do, dennis</a>
            | <time datetime="Mon 28 October 2019">Mon 28 October 2019</time>
        </span>
        <!-- TODO : Modified check -->
        
            <div class="post-cover cover" style="background-image: url('/assets/head_cover_articles.jpg')">            
        
      </div>    
    </header>    

  <section id="wrapper">
    <a class="hidden-close"></a>

    <!-- Post content -->
    <main class="content" role="main">
        <article class="post">
        <div class="inner">
            <section class="post-content">
                <div class="section" id="sharpestminds-project-series-part-6-imputation-of-missing-data">
<h2>SharpestMinds Project Series Part 6: Imputation of Missing Data</h2>
<p>If you are new to this post and would like some context, I'd highly suggest you read through the previous posts of this project series, as this is the sixth post of this series:</p>
<ul class="simple">
<li><a class="reference external" href="/2019/09/sharpestminds-project-part-1.html">Part 1 - Introduction</a></li>
<li><a class="reference external" href="/2019/10/sharpestminds-project-part-2.html">Part 2 - Background, Loading, EDA</a></li>
<li><a class="reference external" href="/2019/10/sharpestminds-project-part-3.html">Part 3 - More Exploratory Data Analysis</a></li>
<li><a class="reference external" href="/2019/10/sharpestminds-project-part-4.html">Part 4 - Dropping Data</a></li>
<li><a class="reference external" href="/2019/10/sharpestminds-project-part-5.html">Part 5 - Categorical Data Encoding</a></li>
</ul>
<p>In the previous post, we completed the necessary preprocessing methods that were required of dealing a variety of categorical data types (nominal, binary, and ordinal) and developed an encompassing transformation at the end to encode the mappings for our data points that remained after the initial preprocessing steps. During the previous post, we separated the numeric data from our categorical data to first work with the categorical features. This is the sixth post of my SharpestMinds project series talk about missing data values and how to come up with a smarter way to go about dealing with them. If you want to follow along with the full codebase in the Jupyter IPython Notebook, you can do so at the <a class="reference external" href="https://github.com/SJHH-Nguyen-D/sharpestminds-project">link to the repo</a>). This is going to be a brief but insightful one, so let's get into it.</p>
<div class="section" id="imputation-of-missing-values">
<h3>Imputation of Missing Values</h3>
<p>If you've been following allow since the last post, you will know that a large part of our numeric feature values still contain NaN values. Typically in blogs and tutorials which detail handling missings values, use a measure of centrality such as mean, median or mode to fill in for missing numeric values. We'd like to take this one step further in our problem and use a powerful API called <tt class="docutils literal">missingpy</tt> to used 'informed imputation', which you can read the documentation for <a class="reference external" href="https://pypi.org/project/missingpy/">here</a>).</p>
<p>First let's get our data in order:</p>
<div class="highlight"><pre><span></span><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">numeric_df</span><span class="p">,</span> <span class="n">categorical_df</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
<p>Before you can use the <tt class="docutils literal">missingpy</tt> imputation package, you have to install it with: <tt class="docutils literal">pip install missingpy</tt> in terminal.</p>
<pre class="literal-block">
$ pip install missingpy
</pre>
<img alt="connect the dots" class="align-center" src="/assets/connect_the_dots.jpg" style="width: 600px; height: 380px;" />
<p><em>Imputing data: You might as well draw something up that makes sense.</em></p>
<p>Now we can simply call the <tt class="docutils literal">.fit_transform()</tt> method, just like any ol' machine learning model in the <tt class="docutils literal"><span class="pre">scikit-learn</span></tt> library to generate the imputed missing data points. There are different approaches available in the <tt class="docutils literal">missingpy</tt> library for which we can use to to impute values. For our pipeline, I chose to use the K-Nearest Neighbors (KNN) imputer object to predict what the missing values for both the numeric and categorical values are. There is some caution to be had about using this type of imputation method for categorical variables, as they will be using numeric encoding schemes to represent the real-world string values - i.e., those values that are predicted my contain point-values for discrete valued categorical numeric encodings and thus have to be rounded to the nearest integer. There is a fallacy in using imputation of values as such is that discrete real world categories can somehow be adjusted to be another through numeric rounding, which isn't the case. This is something we ought of be aware of when using such a method.</p>
<p>As opposed to using the arithmetic mean (sensitive to outlier values) or mode to impute for missing values,  our basis of imputation uses a notion of 'distance' or 'similarity' between samples using the nearest neighbours algorithm. With a fairly large dataset and many features to impute for, it is oft the case that running this on a single CPU will take a considerable amount of time (though definitely less than 1 day, with todays modern CPUs). We won't go through hyperparameter optimization of the imputer in this example, as this will take an obscene amount of time that I am not willing to wait for with my hardware, however this is something someone with the right resources could attempt to do. We will just be running the KNN Imputer object using 5 nearest neighbours and uniform weighting for our sample neighbor weights.</p>
<div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">impute_missing_for_dataframe</span><span class="p">(</span><span class="n">dataframe</span><span class="p">,</span> <span class="n">target</span><span class="o">=</span><span class="s1">&#39;job_performance&#39;</span><span class="p">):</span>
<span class="sd">&quot;&quot;&quot; The imputer function should be used on a dataframe that has already been numerically encoded &quot;&quot;&quot;</span>
<span class="kn">from</span> <span class="nn">missingpy</span> <span class="k">import</span> <span class="n">KNNImputer</span> <span class="c1">#, MissForest</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">dataframe</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="n">dataframe</span><span class="o">.</span><span class="n">columns</span> <span class="o">!=</span> <span class="n">target</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">dataframe</span><span class="p">[</span><span class="n">target</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>

<span class="c1"># imputer object</span>
<span class="n">knn</span> <span class="o">=</span> <span class="n">KNNImputer</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
                <span class="n">weights</span><span class="o">=</span><span class="s2">&quot;uniform&quot;</span><span class="p">,</span>
                <span class="n">metric</span><span class="o">=</span><span class="s2">&quot;masked_euclidean&quot;</span><span class="p">,</span>
                <span class="n">row_max_missing</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span>
                <span class="n">col_max_missing</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span>
                <span class="n">copy</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">knn_missing_imputation</span> <span class="o">=</span> <span class="n">knn</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">imputed_dataframe</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">knn_missing_imputation</span><span class="p">,</span>
                                 <span class="n">columns</span> <span class="o">=</span> <span class="n">dataframe</span><span class="o">.</span><span class="n">columns</span><span class="p">[</span><span class="n">dataframe</span><span class="o">.</span><span class="n">columns</span> <span class="o">!=</span> <span class="n">target</span><span class="p">])</span>
<span class="n">imputed_dataframe</span><span class="p">[</span><span class="n">target</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
<span class="k">return</span> <span class="n">imputed_dataframe</span>

<span class="n">imputed_df</span> <span class="o">=</span> <span class="n">impute_missing_for_dataframe</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">target</span><span class="o">=</span><span class="s2">&quot;job_performance&quot;</span><span class="p">)</span>
</pre></div>
<p>As a check, we can examine number of remaining missing values in each of the features as such:</p>
<div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">missing_values_checker</span><span class="p">(</span><span class="n">dataframe</span><span class="p">):</span>
<span class="sd">&quot;&quot;&quot; prints a statement if the dataframe contains any missing values &quot;&quot;&quot;</span>
    <span class="n">contains_missing_list</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">dataframe</span><span class="o">.</span><span class="n">columns</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">dataframe</span><span class="p">[</span><span class="n">col</span><span class="p">]</span><span class="o">.</span><span class="n">isnull</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">contains_missing_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">dataframe</span><span class="p">[</span><span class="n">col</span><span class="p">]</span><span class="o">.</span><span class="n">isnull</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">())</span>
    <span class="k">if</span> <span class="nb">sum</span><span class="p">(</span><span class="n">contains_missing_list</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;There were no missing values remaining after imputation&quot;</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;There were still NaN values remaining in the dataframe&quot;</span><span class="p">)</span>

<span class="n">missing_values_checker</span><span class="p">(</span><span class="n">imputed_df</span><span class="p">)</span>
</pre></div>
<p>Output:</p>
<div class="highlight"><pre><span></span><span class="n">There</span> <span class="n">were</span> <span class="n">no</span> <span class="n">missing</span> <span class="n">values</span> <span class="n">remaining</span> <span class="n">after</span> <span class="n">imputation</span>
</pre></div>
<p>We can also take a look at some of the attributes that had their missing values imputed for. We can also have a look at median and mean values for each attribute and compare them to some of the ones that were generated.</p>
<div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">f</span><span class="s2">&quot;writhome attribute has: {df.writhome.isnull().sum()} missing values&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">writhome</span><span class="o">.</span><span class="n">agg</span><span class="p">([</span><span class="s1">&#39;median&#39;</span><span class="p">,</span> <span class="s1">&#39;var&#39;</span><span class="p">,</span> <span class="s1">&#39;std&#39;</span><span class="p">,</span> <span class="s1">&#39;kurt&#39;</span><span class="p">,</span> <span class="s1">&#39;skew&#39;</span><span class="p">]))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">writhome</span><span class="o">.</span><span class="n">describe</span><span class="p">())</span>
<span class="n">missing_writhome</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">numeric_df</span><span class="p">[</span><span class="n">numeric_df</span><span class="o">.</span><span class="n">writhome</span><span class="o">.</span><span class="n">isnull</span><span class="p">()]</span><span class="o">.</span><span class="n">index</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">The top 5 generated values for writhome&quot;</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">missing_writhome</span><span class="p">,</span> <span class="s2">&quot;writhome&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
<p>Output:</p>
<div class="highlight"><pre><span></span>writhome attribute has: <span class="m">0</span> missing values
median    <span class="m">2</span>.446716
var       <span class="m">0</span>.811755
std       <span class="m">0</span>.900975
kurt      <span class="m">2</span>.503343
skew     -0.358559
Name: writhome, dtype: float64
count    <span class="m">14424</span>.000000
mean         <span class="m">2</span>.340815
std          <span class="m">0</span>.900975
min         -0.296028
<span class="m">25</span>%          <span class="m">1</span>.766668
<span class="m">50</span>%          <span class="m">2</span>.446716
<span class="m">75</span>%          <span class="m">2</span>.823340
max          <span class="m">6</span>.104219
Name: writhome, dtype: float64

The top <span class="m">5</span> generated values <span class="k">for</span> writhome
<span class="m">9</span>      <span class="m">2</span>.438870
<span class="m">55</span>     <span class="m">2</span>.438870
<span class="m">148</span>    <span class="m">2</span>.787867
<span class="m">173</span>    <span class="m">2</span>.918247
<span class="m">187</span>    <span class="m">2</span>.787867
Name: writhome, dtype: float64
</pre></div>
<p>As you can see, the missing values for the writhome attribute were realistic enough with the ones at indices [9, 55] falling around the median and [148, 173, 187] falling around the 75% percentile.</p>
<p>Let's take examine another feature such as v8, which is an ordinal variable. Notice how point values were imputed for these supposedly discrete ordinal numeric mappings.</p>
<div class="highlight"><pre><span></span><span class="n">imputed_df</span><span class="o">.</span><span class="n">v8</span><span class="o">.</span><span class="n">unique</span><span class="p">()</span>
</pre></div>
<p>Ouput:</p>
<div class="highlight"><pre><span></span><span class="n">array</span><span class="p">([</span><span class="mf">1.2</span><span class="p">,</span> <span class="mf">1.4</span><span class="p">,</span> <span class="mf">1.</span> <span class="p">,</span> <span class="mf">2.</span> <span class="p">,</span> <span class="mf">0.</span> <span class="p">,</span> <span class="mf">0.8</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">,</span> <span class="mf">1.6</span><span class="p">,</span> <span class="mf">1.8</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">])</span>
</pre></div>
<p>We can correct for this issue with the rounding function below:</p>
<div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">round_selected_attributes_imputed</span><span class="p">(</span><span class="n">dataframe_to_round</span><span class="p">,</span> <span class="n">dataframe_not_round</span><span class="p">):</span>
    <span class="n">rounded_dataframe</span> <span class="o">=</span> <span class="n">dataframe_to_round</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="o">.</span><span class="n">round</span><span class="p">())</span>
    <span class="n">dataframe</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">rounded_dataframe</span><span class="p">,</span> <span class="n">dataframe_not_round</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">reset_index</span><span class="p">()</span>
    <span class="c1"># dataframe.drop(&quot;index&quot;, axis=1, inplace=True)</span>
    <span class="k">return</span> <span class="n">dataframe</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">round_selected_attributes_imputed</span><span class="p">(</span><span class="n">imputed_df</span><span class="p">[</span><span class="n">categorical_df</span><span class="o">.</span><span class="n">columns</span><span class="p">],</span> <span class="n">imputed_df</span><span class="p">[[</span><span class="n">col</span> <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">imputed_df</span><span class="o">.</span><span class="n">columns</span> <span class="k">if</span> <span class="n">col</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">categorical_df</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>
</pre></div>
<p>Using the <tt class="docutils literal">.head()</tt> method on our dataframe yields a beautifully, cleaned and complete-looking dataframe with no NaN values and the values are valid.</p>
<img alt="dataframe head after imputation with imputer" class="align-center" src="/assets/data_visualizations/dataframe_head_after_imputation.jpg" style="width: 881px; height: 174px;" />
<div class="section" id="conclusion">
<h4>Conclusion</h4>
<p>Although it was brief, the amount of work and effort that went into sorting out the kinks in my code could not be understated but that goes without saying. What can I say. It was a learning experience and the best way to learn is through failure and trial.</p>
<p>In any case, in this post, we covered the preparation for imputation and the actual imputation of missing values for our dataset with the missingpy.KNNImputer doing the heavy lifting for us. In the <a class="reference external" href="/2019/10/sharpestminds-project-part-7.html">next post</a>, we will cover the feature selection step, which will also be a relatively brief post. Stay tuned! Until next time!</p>
<p>A bonus picture of my cat for these trying times.</p>
<img alt="CoCo the cat" class="align-center" src="/assets/cocos_bizarre_adventure.jpg" style="width: 518px; height: 691px;" />
</div>
</div>
</div>

            </section>

            <section class="post-info">
                <div class="post-share">
                    <a class="twitter" href="https://twitter.com/share?text=Ever wondered what your employee performance score would be? Part 6: Imputation of Missing Data&amp;url=/2019/10/sharpestminds-project-part-6.html" onclick="window.open(this.href, 'twitter-share', 'width=550,height=235');return false;">
                    <i class="ic ic-twitter"></i><span class="hidden">Twitter</span>
                    </a>
                    <a class="facebook" href="https://www.facebook.com/sharer/sharer.php?u=/2019/10/sharpestminds-project-part-6.html" onclick="window.open(this.href, 'facebook-share','width=580,height=296');return false;">
                    <i class="ic ic-facebook"></i><span class="hidden">Facebook</span>
                    </a>
                    <a class="googleplus" href="https://plus.google.com/share?url=/2019/10/sharpestminds-project-part-6.html" onclick="window.open(this.href, 'google-plus-share', 'width=490,height=530');return false;">
                    <i class="ic ic-googleplus"></i><span class="hidden">Google+</span>
                    </a>
                    <div class="clear"></div>
                </div>

                <aside class="post-tags">
<a href="/tag/sharpestminds-project">sharpestminds-project</a><a href="/tag/data-science">data science</a><a href="/tag/projects">projects</a><a href="/tag/employee-performance">employee performance</a><a href="/tag/preprocessing">preprocessing</a><a href="/tag/missing-data">missing data</a><a href="/tag/imputation">imputation</a><a href="/tag/impute">impute</a><a href="/tag/missingpy">missingpy</a>                </aside>

                <div class="clear"></div>

 

                </section>


                <aside class="post-nav">
                    <div class="clear"></div>
                </aside>

            </div>
        </article>
    </main>
      <!-- TODO : Body class -->
    <div id="body-class" style="display: none;" class=""></div>
  
    <footer id="footer">
      <div class="inner">
        <section class="credits">
          <span class="credits-theme">Theme <a href="https://github.com/arulrajnet/attila" rel="nofollow">Attila</a></span>
          <span class="credits-software">Published with <a href="https://github.com/getpelican/pelican" rel="nofollow">Pelican</a></span>
        </section>
      </div>
    </footer>
  </section>

  <script type="text/javascript" src="/theme/js/script.js"></script>
  
</body>
</html>